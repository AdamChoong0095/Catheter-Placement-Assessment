{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/louisechilds/ADS2002-Catheter/blob/main/Catheter_file_management.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omzH-Nx4eiEf"
   },
   "source": [
    "# Catheter file management\n",
    "This notebook should only be executed once. It imports a copy of the images files directly from the RANCZR source to a specifically structured directory in our local drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mITyv5QBeiZC",
    "outputId": "204f79c0-d223-43b1-8756-309a62333e47"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "RS=42#can change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FOMhORVifDkM"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "train_annots=pd.read_csv('train_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XPU7-xq6NSnf"
   },
   "outputs": [],
   "source": [
    "#ChatGpt: delete all files in nested directory\n",
    "def remove_files_in_folder(folder_path):\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                os.remove(file_path)\n",
    "        print(\"All files in the folder and its subdirectories have been removed.\")\n",
    "    else:\n",
    "        print(f\"The folder '{folder_path}' does not exist or is not a directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PjFmY-TVfGnx"
   },
   "outputs": [],
   "source": [
    "#set file name\n",
    "def set_files_on_dataframe(df,tag='StudyInstanceUID'):\n",
    "  '''\n",
    "  df: target data frame\n",
    "  tag: StudyInstanceUID\n",
    "  '''\n",
    "  if 'image_file' not in df.columns:\n",
    "    df['image_file']=''\n",
    "  for i,row in df.iterrows():\n",
    "    if '.jpg' not in row[tag]:\n",
    "      path=row[tag]+'.jpg'\n",
    "      df._set_value(i,'image_file',path)\n",
    "    elif '.jpg' in row[tag]:\n",
    "      path=row[tag]\n",
    "      df._set_value(i,'image_file',path)\n",
    "  return df\n",
    "source='/projects/sc73/ranzcr-clip-catheter-line-classification/train'\n",
    "import shutil\n",
    "#moves a copy of image files to target directory\n",
    "def copy_files(destination_directory,source_directory,image_files):\n",
    "  '''\n",
    "  image files argument is a list of image files to move\n",
    "  '''\n",
    "  # Iterate through the image files and move them to the destination directory\n",
    "  for image_file in image_files:\n",
    "      source_path = os.path.join(source_directory,image_file)\n",
    "      destination_path = os.path.join(destination_directory,image_file)\n",
    "      # Check if the destination file already exists, and if it does, rename it to avoid overwriting\n",
    "      if os.path.exists(destination_path):\n",
    "          base, extension = os.path.splitext(image_file)\n",
    "          count = 1\n",
    "          while os.path.exists(destination_path):\n",
    "              new_filename = f\"{base}_{count}{extension}\"\n",
    "              destination_path = os.path.join(destination_directory, new_filename)\n",
    "              count += 1\n",
    "      # Move the image file to the destination directory\n",
    "      if os.path.exists(destination_path):\n",
    "        print(f\"File '{image_file}' already exists in the destination directory. Skipping...\")\n",
    "      else:\n",
    "        # Move the image file to the destination directory\n",
    "        shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dumd0q85ffyD"
   },
   "source": [
    "The following function will assume a train-validation-split and move a copy of images to target locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "urVmPlHdfuK1"
   },
   "outputs": [],
   "source": [
    "def form_trval_dir(origin,train_dir,val_dir,cath_type,sample):\n",
    "  '''\n",
    "  args\n",
    "  -origin: source file\n",
    "  -train/test/val dir: location of folders containing files for testing training, etc.\n",
    "  -cath_typle: catheter type we test on\n",
    "  -sample: must only use annotations file with one type of catheter\n",
    "  '''\n",
    "  train,validate = train_test_split(sample, test_size=0.2,random_state=RS)\n",
    "  '''\n",
    "  splits data into a train and validate set, testing will be done on non-annotated images\n",
    "  must match certain directory structure to work\n",
    "  dataframe must match certain structure to work see above\n",
    "  '''\n",
    "  train_normal=train[train['label'] == cath_type+' - Normal']\n",
    "  train_abnormal=train[train['label'] == cath_type+' - Abnormal']\n",
    "  train_borderline=train[train['label'] == cath_type+' - Borderline']\n",
    "  validate_normal=validate[validate['label'] == cath_type+' - Normal']\n",
    "  validate_abnormal=validate[validate['label'] == cath_type+' - Abnormal']\n",
    "  validate_borderline=validate[validate['label'] == cath_type+' - Borderline']\n",
    "\n",
    "  train_norm_dir=train_dir+'/Normal'\n",
    "  train_border_dir=train_dir+'/Borderline'\n",
    "  train_ab_dir=train_dir+'/Abnormal'\n",
    "  val_norm_dir=val_dir+'/Normal'\n",
    "  val_border_dir=val_dir+'/Borderline'\n",
    "  val_ab_dir=val_dir+'/Abnormal'\n",
    "\n",
    "  train_list_normal=train_normal['image_file'].tolist()\n",
    "  train_list_abnormal=train_abnormal['image_file'].tolist()\n",
    "  train_list_borderline=train_borderline['image_file'].tolist()\n",
    "  val_list_normal=validate_normal['image_file'].tolist()\n",
    "  val_list_abnormal=validate_abnormal['image_file'].tolist()\n",
    "  val_list_borderline=validate_borderline['image_file'].tolist()\n",
    "\n",
    "  copy_files(destination_directory=train_border_dir,source_directory=origin,image_files=train_list_borderline)\n",
    "  copy_files(destination_directory=train_norm_dir,source_directory=origin,image_files=train_list_normal)\n",
    "  copy_files(destination_directory=train_ab_dir,source_directory=origin,image_files=train_list_abnormal)\n",
    "  copy_files(destination_directory=val_border_dir,source_directory=origin,image_files=val_list_borderline)\n",
    "  copy_files(destination_directory=val_norm_dir,source_directory=origin,image_files=val_list_normal)\n",
    "  copy_files(destination_directory=val_ab_dir,source_directory=origin,image_files=val_list_abnormal)\n",
    "\n",
    "  return 'Done'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3ttMFKbym_fi"
   },
   "outputs": [],
   "source": [
    "merged = train.merge(train_annots, on='StudyInstanceUID', how='left', indicator=True)\n",
    "# Keep only the rows that are not in both DataFrames (left_only)\n",
    "test = merged[merged['_merge'] == 'left_only']\n",
    "# Drop the indicator column and reset the index if needed\n",
    "test = test.drop(columns=['_merge','label','data']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3xczFMKvxBnL"
   },
   "outputs": [],
   "source": [
    "def clean_dataframe(df,cath_type):\n",
    "    '''\n",
    "    only runs for train, not train annotations\n",
    "    '''\n",
    "    if cath_type == 'CVC' or cath_type == 'ETT':\n",
    "        dataframe=df[['StudyInstanceUID',cath_type+' - Abnormal',cath_type+' - Normal',cath_type+' - Borderline','image_file']]\n",
    "        dataframe=dataframe.drop(dataframe[(dataframe[cath_type+' - Abnormal'] == 0) & (dataframe[cath_type+' - Normal'] == 0) & (dataframe[cath_type+' - Borderline'] == 0)].index)\n",
    "        dataframe=dataframe.drop(dataframe[(dataframe[cath_type+' - Abnormal'] == 1) & (dataframe[cath_type+' - Normal'] == 1)].index)\n",
    "        dataframe=dataframe.drop(dataframe[(dataframe[cath_type+' - Borderline'] == 1) & (dataframe[cath_type+' - Normal'] == 1)].index)\n",
    "        dataframe=dataframe.drop(dataframe[(dataframe[cath_type+' - Abnormal'] == 1) & (dataframe[cath_type+' - Borderline'] == 1)].index)\n",
    "    elif cath_type == 'NGT':\n",
    "        dataframe=df[['StudyInstanceUID','NGT - Abnormal','NGT - Normal','NGT - Borderline','NGT - Incompletely Imaged','image_file']]\n",
    "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Abnormal'] == 0) & (dataframe['NGT - Normal'] == 0) & (dataframe['NGT - Borderline'] == 0) & (dataframe['NGT - Incompletely Imaged']==0)].index)\n",
    "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Incompletely Imaged']==1)].index)\n",
    "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Abnormal'] == 1) & (dataframe['NGT - Normal'] == 1)].index)\n",
    "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Borderline'] == 1) & (dataframe['NGT - Normal'] == 1)].index)\n",
    "        dataframe=dataframe.drop(dataframe[(dataframe['NGT - Abnormal'] == 1) & (dataframe['NGT - Borderline'] == 1)].index)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5x6110hhWSp"
   },
   "source": [
    "Create the structure of the directory first before executing. For more information, consult with ChatGPT on how to format a directory for tensorflow supervised learning methods. Remember that we are only using annotated images for training and validating. Perhaps for testing we will use non-annotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ChFX4NKahjVK"
   },
   "outputs": [],
   "source": [
    "#artifically balance the data by selecting a third of images to be normal, a third of images to be abnormal and a third of images to be borderline\n",
    "#discount incomplete images for the reasons stated in other notebook\n",
    "test=set_files_on_dataframe(test)\n",
    "train_annots=set_files_on_dataframe(train_annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gNWs7WQey97c"
   },
   "outputs": [],
   "source": [
    "#for simplicity only use UIDs with at most one of each type of catheter placement\n",
    "cvc_annots_normal=train_annots[train_annots['label']=='CVC - Normal']\n",
    "cvc_selection_normal=cvc_annots_normal.head(500)\n",
    "cvc_selection_normal = cvc_selection_normal.drop_duplicates(subset=['image_file'], keep='first')\n",
    "cvc_annots_abnormal=train_annots[train_annots['label']=='CVC - Abnormal']\n",
    "cvc_selection_abnormal=cvc_annots_abnormal.head(500)\n",
    "cvc_selection_abnormal = cvc_selection_abnormal.drop_duplicates(subset=['image_file'], keep='first')\n",
    "cvc_annots_borderline=train_annots[train_annots['label']=='CVC - Borderline']\n",
    "cvc_selection_borderline=cvc_annots_borderline.head(500)\n",
    "cvc_selection_borderline = cvc_selection_borderline.drop_duplicates(subset=['image_file'], keep='first')\n",
    "#must make sure this occurs when selecting rows by checking lengths of list of unique UIDs against length of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "K5JJB_JULs2_",
    "outputId": "75ee343f-560c-4c7d-d891-ceef9a6338e3"
   },
   "outputs": [],
   "source": [
    "#pre select rows\n",
    "cvc_selection=pd.concat([cvc_selection_normal, cvc_selection_abnormal,cvc_selection_borderline], axis=0)\n",
    "cvc_selection.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xQI7cG7PUHR1"
   },
   "outputs": [],
   "source": [
    "#for simplicity only use UIDs with at most one of each type of catheter placement\n",
    "#adjustable size parameters for number of images\n",
    "ett_annots_normal=train_annots[train_annots['label']=='ETT - Normal']\n",
    "ett_selection_normal=ett_annots_normal.head(500)\n",
    "ett_selection_normal = ett_selection_normal.drop_duplicates(subset=['image_file'], keep='first')\n",
    "ett_annots_abnormal=train_annots[train_annots['label']=='ETT - Abnormal']\n",
    "ett_selection_abnormal=ett_annots_abnormal.head(500)\n",
    "ett_selection_abnormal = ett_selection_abnormal.drop_duplicates(subset=['image_file'], keep='first')\n",
    "ett_annots_borderline=train_annots[train_annots['label']=='ETT - Borderline']\n",
    "ett_selection_borderline=ett_annots_borderline.head(500)\n",
    "ett_selection_borderline = ett_selection_borderline.drop_duplicates(subset=['image_file'], keep='first')\n",
    "#must make sure this occurs when selecting rows by checking lengths of list of unique UIDs against length of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "IObsGVUZVCqS",
    "outputId": "1b05b372-7957-4b07-d914-ab5371d13b60"
   },
   "outputs": [],
   "source": [
    "ett_selection=pd.concat([ett_selection_normal, ett_selection_abnormal,ett_selection_borderline], axis=0)\n",
    "ett_selection.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZtSMKIQkWmyL"
   },
   "outputs": [],
   "source": [
    "#for simplicity only use UIDs with at most one of each type of catheter placement\n",
    "ngt_annots_normal=train_annots[train_annots['label']=='NGT - Normal']\n",
    "ngt_selection_normal=ngt_annots_normal.head(500)\n",
    "ngt_selection_normal = ngt_selection_normal.drop_duplicates(subset=['StudyInstanceUID'], keep='first')\n",
    "ngt_annots_abnormal=train_annots[train_annots['label']=='NGT - Abnormal']\n",
    "ngt_selection_abnormal=ngt_annots_abnormal.head(500)\n",
    "ngt_selection_abnormal = ngt_selection_abnormal.drop_duplicates(subset=['StudyInstanceUID'], keep='first')\n",
    "ngt_annots_borderline=train_annots[train_annots['label']=='NGT - Borderline']\n",
    "ngt_selection_borderline=ngt_annots_borderline.head(500)\n",
    "ngt_selection_borderline = ngt_selection_borderline.drop_duplicates(subset=['StudyInstanceUID'], keep='first')\n",
    "#must make sure this occurs when selecting rows by checking lengths of list of unique UIDs against length of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2YyV8ifdXoGy",
    "outputId": "ebecf2fc-575a-4269-a45c-53a0e7cb2725"
   },
   "outputs": [],
   "source": [
    "ngt_selection=pd.concat([ngt_selection_normal, ngt_selection_abnormal,ngt_selection_borderline], axis=0)\n",
    "ngt_selection.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LjjXQzgec2I9"
   },
   "outputs": [],
   "source": [
    "#check quantity of images in a given folder is correct\n",
    "def count_files_in_directory(directory):\n",
    "    file_count = 0\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_count += 1\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFXbmaM0Xqj0",
    "outputId": "6e125cab-998e-40e4-96ad-ba99241781b7"
   },
   "outputs": [],
   "source": [
    "test_cvc=clean_dataframe(test,'CVC')\n",
    "test_ngt=clean_dataframe(test,'NGT')\n",
    "test_ett=clean_dataframe(test,'ETT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VaezazXflgGC"
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "def form_test_dir(cath_type,test_dir,origin,quant,test,test_size=0.2):\n",
    "  '''\n",
    "  can only use rows without annotations in the train csv\n",
    "  moves images into a TEST folder\n",
    "  samples random rows from extended test data\n",
    "  quant: number of images in both training and validating folders\n",
    "  test: data frame with catheter, eg. see test_ett\n",
    "  '''\n",
    "  random.seed(RS)\n",
    "  test_sample=test.sample(n=ceil(test_size*quant),replace=False)\n",
    "  test_normal=test_sample[test_sample[cath_type+' - Normal'] == 1]\n",
    "  test_abnormal=test_sample[test_sample[cath_type+' - Abnormal'] == 1]\n",
    "  test_borderline=test_sample[test_sample[cath_type+' - Borderline'] == 1]\n",
    "  test_norm_dir=test_dir+'/Normal'\n",
    "  test_border_dir=test_dir+'/Borderline'\n",
    "  test_ab_dir=test_dir+'/Abnormal'\n",
    "\n",
    "  test_list_normal=test_normal['image_file'].tolist()\n",
    "  test_list_abnormal=test_abnormal['image_file'].tolist()\n",
    "  test_list_borderline=test_borderline['image_file'].tolist()\n",
    "  copy_files(destination_directory=test_border_dir,source_directory=origin,image_files=test_list_borderline)\n",
    "  copy_files(destination_directory=test_norm_dir,source_directory=origin,image_files=test_list_normal)\n",
    "  copy_files(destination_directory=test_ab_dir,source_directory=origin,image_files=test_list_abnormal)\n",
    "  return 'Done, files moved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "d69w-ww3mYzp"
   },
   "outputs": [],
   "source": [
    "cvc_test_directory='images_split/CVC/test'\n",
    "ett_test_directory='images_split/ETT/test'\n",
    "ngt_test_directory='images_split/NGT/test'\n",
    "cvc_val_directory='images_split/CVC/validate'\n",
    "ngt_val_directory='images_split/NGT/validate'\n",
    "ett_val_directory='images_split/ETT/validate'\n",
    "cvc_train_directory='images_split/CVC/train'\n",
    "ngt_train_directory='images_split/NGT/train'\n",
    "ett_train_directory='images_split/ETT/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JPXyCbjCofOI",
    "outputId": "bc9ab232-f632-4ab0-8ad8-52c2d57ca43b"
   },
   "outputs": [],
   "source": [
    "n_amount,e_amount,c_amount=len(ngt_selection),len(ett_selection),len(cvc_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rwcm2iXzrle-",
    "outputId": "48960be0-260d-4bf5-f9de-de3bb6ab2535"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30083"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_files_in_directory(source)#no files removed from original source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(train_dir,val_dir,test_dir,test_size,cath_type,sample,origin,quant,test):\n",
    "    '''\n",
    "    see args of previous two functions\n",
    "    '''\n",
    "    remove_files_in_folder(train_dir)\n",
    "    remove_files_in_folder(test_dir)\n",
    "    form_trval_dir(origin,train_dir,val_dir,cath_type,sample)\n",
    "    form_test_dir(cath_type,test_dir,origin,quant,test,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in the folder and its subdirectories have been removed.\n",
      "All files in the folder and its subdirectories have been removed.\n"
     ]
    }
   ],
   "source": [
    "train_dir,val_dir,test_dir=cvc_train_directory,cvc_val_directory,cvc_test_directory\n",
    "test_size=0.2\n",
    "cath_type='CVC'\n",
    "sample=cvc_selection\n",
    "origin=source\n",
    "quant=c_amount\n",
    "test=test_cvc\n",
    "train_val_test_split(train_dir,val_dir,test_dir,test_size,cath_type,sample,origin,quant,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in the folder and its subdirectories have been removed.\n",
      "All files in the folder and its subdirectories have been removed.\n"
     ]
    }
   ],
   "source": [
    "train_dir,val_dir,test_dir=ett_train_directory,ett_val_directory,ett_test_directory\n",
    "test_size=0.2\n",
    "cath_type='ETT'\n",
    "sample=ett_selection\n",
    "origin=source\n",
    "quant=e_amount\n",
    "test=test_ett\n",
    "train_val_test_split(train_dir,val_dir,test_dir,test_size,cath_type,sample,origin,quant,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in the folder and its subdirectories have been removed.\n",
      "All files in the folder and its subdirectories have been removed.\n"
     ]
    }
   ],
   "source": [
    "train_dir,val_dir,test_dir=ngt_train_directory,ngt_val_directory,ngt_test_directory\n",
    "test_size=0.2\n",
    "cath_type='NGT'\n",
    "sample=ngt_selection\n",
    "origin=source\n",
    "quant=n_amount\n",
    "test=test_ngt\n",
    "train_val_test_split(train_dir,val_dir,test_dir,test_size,cath_type,sample,origin,quant,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76a7Q631rGV2"
   },
   "source": [
    "Done! Now we can use the current directory to map out coordinates during training and validating of annotated images and then test on images that are not annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30083"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_files_in_directory(source)#no files removed from original source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNcuhyku7N7NGWeSJTWAhWQ",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
